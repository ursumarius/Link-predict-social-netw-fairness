{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CY3JqGDacWeE"
   },
   "source": [
    "<h1><center> Lab 5: Network (Data) Science and Assignment 2 Support </center></h1>\n",
    "\n",
    "Assignment 2 will combine supervised learning on networks with an essay to reflect on the ethical implications of data science. In this notebook, you can practice with network analysis (community detection and link prediction).\n",
    "\n",
    "You can also use parts of this notebook as a starting point for your assignment: the final part of this notebook can help you to import network data, perform feature engineering and output your predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jH0T4PK3cWeG"
   },
   "source": [
    "<h2> Community detection </h2>\n",
    "\n",
    "The first task we will consider is community detection. This is one example of unsupervised learning with network data. Community detection methods are helpful to detect communities (also known as clusters of modules) based on network structure, such as strongly connected groups of nodes: groups of friends in social, academic sub-communities in co-authorship networks, groups of related web-pages, groups of functionally similar units in metabolic networks.\n",
    "\n",
    "Here you'll find some portions of code that you can use to perform Community Detection analysis (discussed in [Lecture 7](https://canvas.uva.nl/courses/45979/files/11537488?module_item_id=2187507)). We're going to use the example of the Zachary's Karate Club introduced in Lecture 8. You can find more details about this example [here](https://en.wikipedia.org/wiki/Zachary%27s_karate_club)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AFZbp-U4cWeG"
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generate a network (NetworkX already provides a method to extract the Zachary's Karate Club data)\n",
    "G = nx.karate_club_graph()\n",
    "\n",
    "# Lets displace nodes following a Directed Force algorithm (remember Lecture 4, on Data Viz, and Lab 2 Aux)\n",
    "pos = nx.spring_layout(G)\n",
    "\n",
    "# Draw the original graph\n",
    "nx.draw(G, pos=pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7T6C8jdCcWeH"
   },
   "source": [
    "We're now going to play with an implementation of Community Detection offered by NetworkX, which will follow the same principles of Modularity Maximization lectured in [Lecture 7](https://canvas.uva.nl/courses/45979/files/11537488?module_item_id=2187507).\n",
    "\n",
    "You can find extra details about function <code>greedy_modularity_communities</code> [here](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.community.modularity_max.greedy_modularity_communities.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PbCOIO_pcWeH"
   },
   "outputs": [],
   "source": [
    "from networkx.algorithms.community import greedy_modularity_communities\n",
    "\n",
    "#the function will return a partition of nodes\n",
    "c = list(greedy_modularity_communities(G, resolution=0.8))\n",
    "\n",
    "print(c)\n",
    "\n",
    "#we can inspecte the first element of the partition (e.g., nodes on community 1)\n",
    "sorted(c[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c8Q5A4yucWeI"
   },
   "source": [
    "**Q1: How many communities are identified? What is the impact of parameter resolution (now set to 0.8) on this value?**\n",
    "\n",
    "(check the  greedy_modularity_communities documentation pointed above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hS8qgR_QcWeI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8EdDI0PtcWeI"
   },
   "source": [
    "**Q2: Can you plot the network with nodes colores based on communities?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v_wgzazTcWeI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YSnFfC3HcWeI"
   },
   "source": [
    "<h2> Link Prediction - Auxiliary functions Assignment 2 </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TdVPpt1bcWeI"
   },
   "source": [
    "The next task we consider is link prediction. Link prediction will be at the core of your [Assignment 2](https://canvas.uva.nl/courses/45979/assignments/537063).\n",
    "\n",
    "Predicting links on a network is fundamental to predict future connections in social networks or discover hidden connections in incomplete network data. You can find more info about link prediction on [Wikipedia](https://en.wikipedia.org/wiki/Link_prediction).\n",
    "\n",
    "\n",
    "There are many approaches to link prediction, from simpler ones (based on heuristics and network similarity measures, also called topology-based approaches) to more complex ones (based on graph embeddings and deep learning).\n",
    "\n",
    "The supervised learning methods you learned so far can also be used to perform link prediction. In your Assignment you should use supervised learning, in particular the techniques discussed in the course, to tackle the problem of link prediction. In the example below, you will try to predict links in the Karate Club network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xP5sV5sccWeI"
   },
   "outputs": [],
   "source": [
    "# Importing and exporting network data\n",
    "import pandas as pd\n",
    "\n",
    "# We will start by exporting and importing the Karate Club network\n",
    "# This example can be useful for you to import the network data used in Assignment 2\n",
    "\n",
    "edges = []\n",
    "for edg in nx.edges(G):\n",
    "    edges.append(edg)\n",
    "\n",
    "dfEdges = pd.DataFrame(edges)\n",
    "dfEdges.to_csv(\"karateclub.edgelist\", index=False, header=False)\n",
    "\n",
    "G1 = nx.read_edgelist(\"karateclub.edgelist\", data=False, nodetype = int, delimiter=',') # import\n",
    "nx.draw(G1, pos=pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MODnYSRycWeI"
   },
   "source": [
    "Above, we are creating a network by importing a list of edges in the exact same format as edges_train.edgelist for Assignment 2.\n",
    "\n",
    "In the code below, we will create a training set by removing nEdgesRemove random edges from the network above. The removed links will be visualised in red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fcDFum7FcWeI"
   },
   "outputs": [],
   "source": [
    "# We will now create a training set by removing nEdgesRemove random edges from the network above\n",
    "# 10 edges will be removed\n",
    "nEdgesRemove = 10\n",
    "\n",
    "# Sample random edges\n",
    "allEdges = np.array(G1.edges)\n",
    "np.random.seed(seed=42)\n",
    "selectEdges = np.random.choice(np.arange(allEdges.shape[0]), nEdgesRemove)\n",
    "edgesToRemove = allEdges[selectEdges]\n",
    "\n",
    "# Create new graph (H) without selected edges\n",
    "H = G1.copy()\n",
    "H.remove_edges_from(edgesToRemove)\n",
    "\n",
    "# Visualize the links that were removed (in red)\n",
    "# Use the same colors as defined above to color communities\n",
    "for i in range(len(c)):\n",
    "    nx.draw_networkx_nodes(G, pos, nodelist=sorted(c[i]))\n",
    "\n",
    "nx.draw_networkx_edges(G, pos, edge_color='red')\n",
    "nx.draw_networkx_edges(H, pos, edge_color='black')\n",
    "\n",
    "#Compute number of nodes in the network\n",
    "N = len(list(H.nodes))\n",
    "print(\"The network has \", N, \" nodes\")\n",
    "\n",
    "#Compute number of edges in the network\n",
    "E = len(list(H.edges))\n",
    "print(\"The network has \", E, \" edges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KEfFEfKDcWeJ"
   },
   "source": [
    "After importing the network the next task is to define the features that seem important to predict the occurence of links.\n",
    "\n",
    "This is the step where feature engineering can take place. We are using [preferential attachment](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.link_prediction.preferential_attachment.html#networkx.algorithms.link_prediction.preferential_attachment) as one feature to infer links. This might not be the most interesting feature to predict links in this social network. Other possible features can be constructed by metrics you can learn about in the NetworkX documentation ([here](https://networkx.org/documentation/stable/reference/algorithms/link_prediction.html)).\n",
    "\n",
    "**Q2: Which other features can you use? Adapt function *getFeature* to consider other feastures associated with each edge.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K7m7KXqWcWeJ"
   },
   "outputs": [],
   "source": [
    "# Use Preferential Attachment between nodes as a feature\n",
    "pa = np.zeros((N,N))\n",
    "\n",
    "preds = nx.preferential_attachment(H, [(i,j) for i in range(N) for j in range(N)])\n",
    "for u, v, p in preds:\n",
    "    pa[u,v] = p\n",
    "\n",
    "# Generate features from edge endpoints\n",
    "# Input: getFeature(graph, node_i, node_j)\n",
    "def getFeature(G, i, j): \n",
    "    return ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_OHvObrzcWeJ"
   },
   "source": [
    "The next step is to create a training set. You can do this by using all visible edges in network H (positive examples) and some non-existing edges in network H (negative examples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9VCr3rkicWeJ"
   },
   "outputs": [],
   "source": [
    "# Let us now create a training set where X will correspond to features for each possible edge and Y the predciton\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "# Add positive examples where edge exist\n",
    "for (i, j) in H.edges:\n",
    "    X.append(getFeature(H, i, j))\n",
    "    Y.append(1)\n",
    "\n",
    "# Add negative examples where edge does not exist\n",
    "# Reflect: how many negative examples should you include?\n",
    "for kk in range(200):\n",
    "        i = np.random.randint(N)\n",
    "        j = np.random.randint(N)\n",
    "\n",
    "        while H.has_edge(i,j) or i == j:\n",
    "            i = np.random.randint(N)\n",
    "            j = np.random.randint(N)\n",
    "\n",
    "        X.append(getFeature(H, i, j))\n",
    "        Y.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TgV_R3NAcWeJ"
   },
   "source": [
    "**Q3: In the previous code we are adding 200 negative examples (non-existing edges) to our traning set. Is that a reasonable choice? How many positive examples are we considering?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2RaUb3hdcWeJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z3q3GMdDcWeJ"
   },
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.8, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K6e2VcvwcWeJ"
   },
   "outputs": [],
   "source": [
    "# Tune model (Logistic Regression)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = LogisticRegression(random_state=0, C=2.0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "scores = cross_val_score(clf, X_test, y_test, cv=5)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fmwaeXCdcWeJ"
   },
   "source": [
    "**Q4: The previous code trains a Logistic regression with a specific hyper-parameter. Which other learning models could you use, out of the ones discussed in the course? How could you select the best hyper-parameter?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fmwaeXCdcWeJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QjrvJap4cWeJ"
   },
   "source": [
    "Given a list of edges, we should be able to predict its existence. Below we provide an example of importing an input file and returning, for edge, the prediction of the trained model.\n",
    "\n",
    "**Q5: Please complete the missing text to generate the predictions from your model given the input data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hUf7qC1FcWeJ"
   },
   "outputs": [],
   "source": [
    "# Return Solution\n",
    "inpTest = pd.read_csv('aux_assignment2_testInput.csv', sep=',', index_col=\"ID\")\n",
    "inpTest = np.array(inpTest)\n",
    "inp = []\n",
    "\n",
    "for i in inpTest:\n",
    "    inp.append(getFeature(H, i[0], i[1]))\n",
    "\n",
    "predictionsLR = ## Line to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oyq3AfbScWeK"
   },
   "outputs": [],
   "source": [
    "# Output solution\n",
    "pd.DataFrame(predictionsLR).to_csv('aux_assignment2_predictions.csv', index=True, header=[\"prediction\"], index_label=\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XrRyRDOMcWeK"
   },
   "outputs": [],
   "source": [
    "# Evaluate solution\n",
    "\n",
    "# Read predictions\n",
    "y_pred = pd.read_csv('aux_assignment2_predictions.csv', sep=',', index_col=\"ID\")\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "# Read solutions file\n",
    "y = pd.read_csv('aux_assignment2_solution.csv', sep=',', index_col=\"ID\")\n",
    "y = np.array(y)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "print(\"Accuracy (test): %0.3f%% \" % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h3VN_9_HcWeK"
   },
   "source": [
    "**Q6: Reflect on the accuracy value you obtained. What does that mean? Knowing that in the final test set there are 50% of positive examples and 50% of negative examples, what would be the accuracy of a random classifier? What would be the accuracy of a naive classifier always predicting that a link does not exist?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
